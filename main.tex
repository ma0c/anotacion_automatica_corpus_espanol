\documentclass[a4paper,12pt,twoside]{report}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=3cm]{geometry}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{svg}
\usepackage{xcolor}
\usepackage{graphicx}

\title{Anotación automática de un corpus hablado de licencia abierta y larga duración para el lenguaje Español}
\author{Mauricio Collazos}
\date{March 2021}

\begin{document}

\maketitle

\begin{abstract}
    Los recursos abiertos para el procesamiento, reconocimiento, generación y demás tareas relacionadas con las tecnologías del lenguaje hablado son parte fundamental del proceso académico e investigativo. Estos recursos deben contener características muy específicas para la ejecución adecuada de la tarea relacionada, donde los niveles de anotación, duración de las grabaciones, variedad de locutores, balance de género, tamaño del vocabulario, relación de señal/ruido y conjunto de datos para pruebas son fundamentales. A pesar de existir diversos recursos disponibles para realizar las tareas mencionadas, los recursos abiertos para trabajar las tecnologías del hablada en la lengua española son escasos y en muchos casos insuficientes para realizar comparaciones con investigaciones del estado del arte propuestas para otros lenguajes. Este trabajo realiza una exploración de los recursos abiertos para el español y propone mecanismos para segmentar audio libros publicados por voluntarios bajo licencias abiertas en recursos apropiados para el procesamiento de voz.
\end{abstract}


\chapter{Introducción}

\section{Definición del problema}

Los recursos para la investigación de tecnologías del habla son de vital importancia para la generación y validación de nuevo conocimiento en el área. En la actualidad donde la investigación se ha decantado en su mayoría por el aprendizaje de máquina utilizando mecanismos de aprendizaje supervisado, semi supervisado y no supervisado \textcolor{red}{[CITA]}, la calidad de los datos usados para el entrenamiento, validación y pruebas definen en gran medida los resultados de la investigación.

Recursos representativos para realizar tareas comunes como el reconocimiento automático del habla y la síntesis del habla son TIMIT \cite{PriceTheRecognition}, Switchboard \cite{Godfrey1992SWITCHBOARD:Development}, Fisher \cite{CieriTheSpeech-to-Text} y Libri Speech \cite{PanayotovLIBRISPEECH:BOOKS}, recursos anotados desde el nivel fonético hasta el nivel de declaración \textcolor{red}{(acá estoy traduciendo utterance pero no me suena del todo)} altamente citados en investigaciones relacionadas con tecnologías del habla para la lengua inglesa


Aunque se ha probado el uso de recursos multilingues para tareas de reconocimiento de voz, la diferenciación en la articulación de los fonemas hace necesaria el uso de recursos enfocados en el español.

Para la lengua española, los recursos más representativos para realizar tareas relacionadas con procesamiento de voz son Albazyn \cite{CampilloAlbayzinEvaluation}, Fisher Spanish \cite{FischerSpa}, Call Friend \cite{CALLFRIENDSpa}, Call Home \cite{CALLHOMESpa}, DIMEx100\cite{Pineda2004DIMEx100:Spanish}, y mas recientemente Libri Speech español \cite{LibriVox-Spanish}.



El presente trabajo realiza una revisión detallada recursos abiertos para la ejecución de tareas de voz y propone la creación un nuevo recurso basado en grabaciones accesibles en la web de licencias abiertas, utilizando algoritmos de segmentación y alineamiento para la anotación a nivel de sentencia de un corpus de larga duración, gran vocabulario y de múltiples locutores.


\section{Justificación}


Existen múltiples factores importantes que influyen en los resultados de investigación con tareas de voz como el nivel de anotación de los recursos, la relación ruido señal, la variación de locutores, y el tamaño del vocabulario, pero se ha mostrado que el tamaño del corpus es un factor que impacta directamente la precisión de las tareas.

En la tabla \ref{tab:english_corpora} \textcolor{red}{METER COLUMNA DE LICENCIA} se presentan recursos representativos para la lengua inglesa, siendo estos corpus objeto de múltiples investigaciones.

\input{tablas/01_1_corpus_ingles}

Se presenta en contraparte una lista de recursos para la lengua española, donde se ordenan los corpus por duración en horas y se evidencia que el tamaño de estos recursos es significativamente  menor a los de la lengua inglesa.


\input{tablas/01_2_cospus_espanol}

Aunque la brecha entre los lenguajes español e inglés es muy amplia, el lenguaje español no se considera un lenguaje con escasos recursos, pues existen múltiples corpus, bancos de árboles, datos anotados y transcritos, diccionarios y gramáticas formales \cite{CavarGlobalGORILLA}. 

Se ha mostrado de igual manera que la anotación manual de recursos es una tarea costosa \textcolor{red}{[CITA]]}, y por esta razón propuestas de anotación automáticas son mas atractivas por la reducción de costos y esfuerzos empleadas en para la generación de los recursos.

Este trabajo utiliza recursos abiertos publicados bajo licencia Creative Commons en la plataforma Libri Vox \cite{LibriVox} donde voluntarios se coordinan para crear audio libros de textos en el dominio público y publicados en el proyecto Gutenberg \cite{gutenberg}. A la fecha existen mas de 600 libros publicados para el español, los cuales se usarán como insumo para la creación de un corpus abierto de larga duración, múltiples locutores anotado a nivel de sentencia.

\chapter{Revisión de recursos abiertos para el español}

La investigación en tecnologías del habla depende fuertemente en recursos de lenguaje de alta calidad y gran tamaño diseñados para la lengua específica. Los recursos abiertos de este tipo son más escasos en comparación con recursos de pago y la creación de dichos recursos para tareas como reconocimiento y síntesis de voz es costosa, por lo que muchos investigadores optan por crear conjuntos de datos pequeños y enfocados a su investigación.

Para lenguajes diferentes al inglés, la diferencia en disponibilidad de dichos recursos es aún mayor. Este capítulo presenta una compilación de recursos abiertos para tareas relacionados con tecnologías de voz para la lengua española, describiendo cada recurso y proponiendo posibles aplicaciones para cada corpus.

\section{Preámbulo}

Los modelos utilizados regularmente para procesamiento de voz, son considerados dependientes de datos y hambrientos, significando que se requieren cantidades masivas de datos para lograr buenos resultados. En reconocimiento de voz, sistemas como Listen-Attend-Spell de Google \cite{Chiu2018} fue entrenado utilizando mas de 12500 horas de inglés. Adicionalmente estos recursos deben estar anotados finamente, como TIMIT \cite{TIMIT} o Swichboard \cite{Switchboard}; sin embargo, las anotaciones manuales son costosas en esfuerzo y tiempo.

Aunque los esfuerzos para reducir los requerimientos por grandes volúmenes de datos anotados usando aprendizaje semi supervisado \cite{AmazonSemiSupervised} y no supervisado \cite{ZeroResources}, estas aproximaciones requieren una cantidad alta de datos no supervisados.

Estas complicaciones se hacen mas evidentes en lenguas distintas al inglés donde en lenguas como la española, los recursos son limitados en tamaño, variedad y nivel de anotación \cite{HernndezMena2017}. De igual manera, en comparación con el inglés que  tiene lineas base de investigación desde hace mas de dos décadas con corpus como TIMIT \cite{TIMIT}, Switchboard \cite{Switchboard} o Fisher \cite{Fisher}, para el español las líneas bases para investigación no están claramente definidas.

Disponibilidad de los recursos para la investigación es un aspecto fundamental en el desarrollo de prototipos, algoritmos y técnicas. Comparando los recursos disponibles de licencias abiertas y de pago en los catálogos mas reconocidos de recursos de lenguaje, la diferencia evidenciada es enorme. En la tabla \ref{tab:resources_by_langauge} se muestran los recursos publicados por el Linguistic Data Consortium (LDC) y la European Language Resources Association (ELRA), mostrando que el inglés tiene cinco veces mas recursos que el español y el mandarín

\begin{table}[h]
\caption{Recursos para los cinco lenguajes más hablados del mundo \cite{HernndezMena2017}}
\label{tab:resources_by_langauge}
\begin{tabular}{|l|l|l|l|}
\hline
Posicion & Lenguaje & LDC & ELRA \\ \hline
1    & Mandarin & 24  & 6    \\ \hline
2    & Inglés  & 116 & 23   \\ \hline
3    & Español  & 20  & 20   \\ \hline
4    & Hindi    & 9   & 4    \\ \hline
5    & Árabe   & 10  & 32   \\ \hline
\end{tabular}
\end{table}

Este capítulo muestra una revisión de los recursos de licencia abierta para tareas de procesamiento de voz en español, usando como criterios la visibilidad, disponibilidad y el impacto, indicando que existen otros recursos no considerados por falta de los criterios mencionados previamente.


\section{Recursos abiertos para el español}

Esta sección menciona los recursos de lenguaje abiertos para la lengua española con licencias abiertas y distribuidos abiertamente en la web. Un resumen se presenta en la tabla \ref{tab:open_source_spanish_corpus} organizada por fecha de publicación; mostrando características importantes de cada conjunto de datos, como la licencia de distribución, el nivel de anotación, la duración, las condiciones de grabación, el dialecto y la fuente de las grabaciones.

En la tabla \ref{tab:open_source_spanish_corpus} se utilizan las siguientes abreviaciones:  CC BY-SA 4.0 Creative Commons Share A Like v4.0 license, LDC Non-Members LDC User LDC User Agreement for Non-Members, para dialectos: MX Mexicano, ES Peninsular, AR Argentino, CH Chileno, PE Peruano, CO Colombiano, PR Puerto Riqueño, VE Venezuelano.

\include{tablas/02_corpus_abiertos_espanol}

\subsection{DIMEx100}

DIMEx100 es un corpus oral diseñado y grabado por el Instituto de Investigaciones en Matematicas Aplicadas y en Sistemas IIMAS de la Universidad Nacional Autónoma de México UNAM en 2004, utilizando textos del Corpus 230 \cite{Corpus230}, un corpus escrito fonéticamente equilibrado para el español. idioma. Este proyecto fue anotado usando un nuevo diccionario fonético para el español mexicano llamado MEXBET, que mejora la representación de los alófonos del español mexicano en comparación con otros alfabetos fonéticos multilingües como SAMPA y WordNET \cite{mexbet}. El proceso de grabación para DIMEx100 se realizó en un estudio de grabación, con bajo nivel de ruido, con el micrófono ubicado a una distancia homogénea de los altavoces. Se seleccionaron 100 hablantes entre 16 y 36 años siendo 50 hombres y 50 mujeres. La edad media de los hablantes fue de 23 años y todos los hablantes hablan el dialecto mexicano.

Este es un pequeño corpus con equilibrio fonético y de género con un pequeño vocabulario con anotaciones fonéticas, que se puede usar para el reconocimiento de palabras aisladas o bootstrapping para recursos más grandes; sin embargo, todos los hablantes usan el dialecto mexicano, lo que lo hace inclinado para otros dialectos.

\subsection{Heroico}

Heroico es un corpus hablado publicado en 2006 por John Morgan en el Departamento de Lenguas Extranjeras (DFL) y el Centro para el Aprendizaje de Idiomas Mejorado por la Tecnología (CTELL), todas las grabaciones fueron grabadas en El Heroico Colegio Militar y la Academia Militar Mexicana en México. Este corpus tiene un desequilibrio de género y se anota a nivel de enunciado. El corpus de HEROICO está compuesto por 102 hablantes que responden abiertamente a un conjunto de 143 preguntas y leen 75 expresiones de un conjunto de datos compuesto por 205 frases cortas y 519 oraciones simples de notas académicas de la escuela secundaria.

La distribución del corpus Heroico también incluye el subcorpus USMA, registrado en 1997 en el que está compuesto por 206 expresiones fijas leídas por 18 hablantes nativos y no nativos diferentes. La duración total del corpus es de 13 horas. Todas las grabaciones se realizaron con computadoras de escritorio, el ruido está presente en varias grabaciones \cite{heroico}.

Los corpus Heroico y USMA combinados tienen 13 horas de audio, y parte del corpus es habla espontánea en entornos ruidosos y diferentes potencias de señal, lo que permite que este corpus entrene modelos para un reconocimiento de voz robusto. Además, algunos hablantes en el corpus de la USMA no son hablantes nativos de español y hay diferentes dialectos de español que también dan variabilidad para los modelos independientes del hablante.

\subsection{Proyecto CIEMPIESS}

El Corpus de Investigación en Español de México del Posgrado de Ingeniería Eléctrica y Servicio Social de la Universidad Nacional Autónoma de México CIEMPIES-UNAM es un proyecto iniciado en 2012 con el objetivo de desarrollar y compartir herramientas gratuitas y de código abierto para el procesamiento del habla en el idioma español. El proyecto no se limita a la creación de corpus sino a la investigación en tecnologías de habla aplicadas al idioma español \cite{CIEMPIESS-Webpage}. Para la anotación de corpus, el proyecto CIEMPIESS utiliza estudiantes de pregrado para realizar anotaciones manuales, como parte de un requisito para recibir un diploma. Toda la segmentación y anotación se realiza utilizando herramientas de código abierto y corpus final distribuido bajo licencias abiertas. Este proyecto ha publicado varios corpus a lo largo de los años, incluido el corpus original de CIEMPIESS \cite {CIEMPIESS}, CIEMPIESS Light \cite {CIEMPIESS-LIGHT}, CIEMPIESS Balance \cite {CIEMPIESS-BALANCE}, CIEMPIESS Experimentation \cite {CIEMPIESS-Experimentation} y LibriVoxSpanish \cite {LibriVox-Spanish} que se describirán a continuación.

\subsubsection{CIEMPIESS}

El Corpus de Investigación en Español de México del Posgrado de Ingeniería Eléctrica y Servicio Social fue publicado en 2014 por el Departamento de Procesamiento Digital de Señales de la Universidad Nacional Autónoma de México, con el objetivo de crear un corpus hablado para el reconocimiento automático de voz. Todas las grabaciones fueron extraídas de diversos programas de radio emitidos por la Universidad, en total se grabaron 43 programas de una hora, segmentados manualmente y solo las grabaciones fueron de un solo locutor y no se seleccionaron otros sonidos de fondo como música o interferencias. Dando la naturaleza del programa de radio, este corpus contiene discurso continuo y es desequilibrado de género, con 77,86 grabaciones masculinas y solo 22,14 grabaciones femeninas. El corpus completo tiene 16717 grabaciones y tiene una duración total de 17 horas. El proceso de anotación se realizó usando MEXBET y vocales tónicas, además todas las expresiones se alinean por palabra.

\subsubsection{CIEMPIESS Light}

CIEMPIES Light se publicó después de dos años de experimentación con el CIEMPIESS Corpus, el equipo de CIEMPIESS recibió muchos comentarios y se lanzó una nueva versión del corpus original, cambiando el formato de distribución de archivos SPH a archivos WAV, también modificando algunas grabaciones y agregando casi una nueva hora de audio. Esta nueva distribución es compatible con herramientas ASR modernas como Kaldi y CMU Sphinx. La mayoría de las grabaciones originales se conservaron, pero otras se reemplazaron. Este corpus tiene casi 1 hora más de grabaciones.

Este corpus puede considerarse como la versión dos del corpus original de CIEMPIESS, pero mejorado para trabajar con sistemas ASR modernos; y sin utilizar ninguna transcripción fonética, también se discriminan las grabaciones por género y hablante. Este corpus incluye grabaciones de 53 hablantes masculinos y 34 hablantes femeninos. Cada hablante se identifica con un prefijo que indica el género M para masculino y F para femenino y un número consecutivo.

\subsubsection{CIEMPIESS Balance}

Dado que el corpus de CIEMPIESS tiene un desequilibrio de género, se creó un corpus de nueva creación a partir de la misma fuente para equilibrar el corpus de CIEMPIESS LIGHT para tener juntos un corpus combinado de género equilibrado. Este corpus está compuesto por 18 horas y 20 minutos donde 12 horas y 40 segundos son de hablantes mujeres y 5 horas y 40 minutos son de hablantes masculinos.

La distribución de este corpus es similar al corpus CIEMPIES Light, donde las grabaciones se almacenan en formato WAV y discriminadas por género y, como este corpus es una contraparte del corpus CIEMPIESS Light, el corpus CIEMPIES Balance cuenta con 53 Locutoras y 34 locutores masculinos identificado por un prefijo que indica el género M para masculino y F para femenino y un número consecutivo. La duración de la grabación para cada hablante en el corpus de CIEMPIESS Light es similar a la contraparte del género opuesto en el Corpus de equilibrio de CIEMPIESS.

Se recomienda el uso de este corpus junto con el corpus CIEMPIESS Light para tener un corpus más largo con equilibrio de género de casi 36 horas de habla continua.

\ subsubsection {CIEMPIES EXPERIMENTATION }

CIEMPIES Experimentación es un conjunto de tres corpus distribuidos en uno solo, con un corpus para alófonos de equilibrio fonético para el español mexicano, un corpus con solo mujeres hablantes y uno diseñado para ser un corpus de prueba estándar.

CIEMPIESS EXPERIMENTATION - COMPLEMENTARY es un corpus fonéticamente equilibrado para palabras aisladas que contiene una hora de audio anotado usando MEXBET 29 y MEXBET 66, dos anotaciones fonéticas que consideran diferentes alófonos para el idioma español. Este corpus contiene grabaciones de 10 locutores masculinos y 10 locutores femeninos y fue creado para mejorar los motores de reconocimiento de voz que no encontraron ocurrencias de alófonos específicos al entrenar modelos acústicos.

CIEMPIES EXPERIMENTATION  - FEM es un corpus con solo hablantes femeninas, que contiene 13 horas y 54 minutos de grabaciones, 16 de las hablantes femeninas en el corpus son hablantes nativos de México y 5 más son otros dialectos del español, incluidos el venezolano, el argentino y el español de El Salvador. , Español de República Dominicana y otros dialectos clasificados como desconocidos.

CIEMPIES EXPERIMENTATION  - TEST es un corpus con equilibrio de género diseñado para probar aplicaciones de habla, con un total de 8 horas y 8 minutos de grabaciones de 10 hablantes mujeres y 10 hablantes masculinos de 4 horas y 4 minutos cada una.

\subsubsection {Librivox Spanish}

Librivox Spanish es un corpus en español basado en grabaciones abiertas subidas al sitio Librivox \cite{LibriVox}, todos los audiolibros en el dominio público y parte del Proyecto Guttenberg \cite{gutenberg} o liberados al dominio público. El corpus fue anotado manualmente por estudiantes de pregrado como parte de su requerimiento de servicio social en la Universidad Nacional Autónoma de México, tiene un total de 73 horas de audio, balanceado por género con 60 horas de hablantes nativos de español y el resto de hablantes no nativos. . Como este corpus es de colaboración colectiva, las grabaciones tienen una calidad diferente; en la mayoría de los casos, las grabaciones se realizaron en un entorno silencioso y utilizando micrófonos de computadora normales.

Como este corpus se anota manualmente y las grabaciones de audio originales son de dominio público, el corpus en sí se puede utilizar como un corpus de prueba para la segmentación automática de las grabaciones originales. Además, el corpus tiene hablantes con diferentes dialectos, lo que hace que sea apropiado crear sistemas de reconocimiento de voz independientes del hablante.

\subsection{M-AILABS}

M-AILABS Speech Dataset es un corpus hablado creado por Imdat Solak utilizando recursos disponibles abiertamente de LibriVox y Project Guttenberg. El corpus era multilingüe, incluido alemán, inglés estadounidense e inglés británico, español, italiano, ruso ucraniano, francés y polaco.

El subcorpus en español tiene 108 horas de duración y está grabado dividido en tres subcorpus, un corpus femenino de 10 horas, grabado por una hablante mexicana, un corpus masculino de 72 horas, grabado por un argentino y un hispanohablante, y un corpus mixto de 25 horas, grabado por varios hablantes no identificados. . Todas las grabaciones incluidas en este corpus también pertenecen al proyecto LibriVox.

Para anotar a nivel de enunciado las grabaciones de Librivox fuente se utilizó un guión automático para segmentar capítulos, luego se utilizó un servicio en línea Speech To Text para dar una anotación para la señal, posteriormente se comparó el texto fuente con la anotación para la señal proporcionada por el servicio en línea y se realizó una verificación manual para descartar el audio o adaptar la anotación a la señal.

El corpus M-AILABS también tiene diferentes dialectos para el idioma español y fue diseñado originalmente para mejorar los sistemas de reconocimiento automático de voz \cite{M-AILABS}.

\subsection{Google TTS Latin American}

El corpus de Crowdsourcing Latin American Spanish for Low-Resource Text-to-Speech fue creado por Google Research y el Laboratoire de Sciences Cognitives et Psycholinguistique y Graduate School of Engineering de la Universidad de Tokio. El corpus se diseñó para tener un corpus de varios dialectos de alta calidad para los sistemas de texto a voz de América Latina. Este corpus incluye 6 subcorpus para dialectos argentino, chileno, colombiano, peruano, puertorriqueño y venezolano, y un total de 174 hablantes y 37,7 horas de audio. Las oraciones se seleccionaron con base en un sistema de conversación para el español mexicano, pero luego se adaptó eliminando las oraciones específicas del español mexicano. Las oraciones se adaptaron a cada dialecto en particular y solo 30 se mantuvieron como canónicas.

Las grabaciones se realizaron en una cabina vocal portátil con un micrófono de condensador en un entorno cercano al silencio. Este corpus fue diseñado para crear sistemas de síntesis de voz para varios dialectos del español latinoamericano \cite{googleTTSLatinAmericanSpanishCorpus}.

\subsection{Common Voice}

La fundación de software Mozilla, creó a mediados de 2017 una plataforma de recopilación de voz de crowdsourcing para recopilar recursos de voz para crear modelos para su Deep Speech Project, basado en la propuesta de Baidu Deep Speech \cite{deepspeeh}. Usando una plataforma web, los usuarios registran frases cortas y también validan otras grabaciones, teniendo una cantidad cada vez mayor de grabaciones. La última versión fue 5.1 e incluyó 54 idiomas, incluidos inglés, kinyarwanda, alemán, francés, catalán y cabilio con más de 500 horas, español, persa, italiano, ruso, polaco con más de 100 horas y los idiomas restantes con menos de 100 horas.

El conjunto de datos español está compuesto por 521 horas de grabaciones y 290 grabaciones validadas.

A medida que el corpus crece día a día y las validaciones las realiza la misma comunidad, es posible que haya errores en los corpus y también en diferentes condiciones del habla. La idea de este corpus es crear un vocabulario extenso, corpus de múltiples hablantes para alimentar modelos hambrientos de datos para el reconocimiento de voz \cite{Common-Voice}.

\chapter{Creación de recursos de prueba}

Con el objetivo de determinar una línea base para la creación del corpus, se inicia realizando una segmentación de recursos abiertos existentes para medir posteriormente la calidad de las segmentaciones automáticas.

Se define segmentación del audio como el proceso por medio del cual, a partir de una grabación de voz, se identifican las ocurrencias de fonemas, palabras o declaraciones. 

Se realizaron dos anotaciones para el desarrollo de la investigación: una anotación a nivel fonético y otra a nivel de declaración.

Para ambas anotaciones se utilizó el software Praat \cite{Praat} desarrollado por Paul Boersma y David Weenink de la Universidad de Ámsterdam. por medio del cual de manera visual es posible crear archivos de segmentación del audio. Estos archivos usan el formato TextGrid, especificado por la misma herramienta, donde se definen secuencias de elementos que identifican el inicio, finalización y texto encontrado en cada segmento. Estos archivos son almacenados en formato de texto para su facil lectura \cite{TextGrids}

\section{Anotación manual a nivel fonético}

Para esto se realizó una anotación fonética manual sobre grabaciones del Open Speech Corpus \cite{Collazos2015} del subcorpus de palabras aisladas, el cual esta compuesto por 334 palabras distintas grabadas por múltiples locutores con un total de \textcolor{red}{[Cuantas grabaciones tiene este sub corpus y cuantos locutores distintos?]}, seleccioando aleatoriamente 100 palabras distintas y realizando una anotación manual por medio de PRAAT \cite{Praat}.

\include{tablas/03_anotacion_fonetica}

\section{Anotación manual a nivel de sentencia}

También se realizó una anotación a nivel de declaración de los audiolibros de Librivox, seleccionando audios correspondientes a 6 horas de grabacion, sobre los cuales se realizó una segmentación manual basada en símbolos de puntuación \textcolor{red}{[Describir el mecanismo de tokenización]}

\section{Anotación automática a nivel de sentencia usando Libri Vox Spanish}

WIP



\chapter{Segmentación y Alineación automática}

\section{Segmentación basada en silencio}

Cálculo de formantes e intensidad de la señal.

Análisis espectral sin el uso de vectores especiales

Cálculo de threshold de ruido utilizando valores fijos, valores proporcionales a intensidad máxima de la señal y clusters de señal/ruido

\section{Alineación basada en duración de fonemas}

Cálculo de duración promedio de fonemas



\section{Segmentación basada en información fonética de formantes en vocales}

Base teórica de los formantes 1 y 2 para vocales en español

Cálculo observado para formantes 

Gráfica de formante promedio +- desviación estandar sobre grabación vocálica

\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plain}
% \bibliographystyle{apacite}
% \bibliography{bibliography/bibliography}
\bibliography{referencias_ante_proyecto.bib,custom_references_ante_proyecto.bib,references_chapter_1.bib}

\end{document}
